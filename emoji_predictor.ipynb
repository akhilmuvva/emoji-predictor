{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL5i63LwGM2313FAeEqNzK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilmuvva/emoji-predictor/blob/main/emoji_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ijVNcShwZH2U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.DataFrame({\n",
        "    'text': [\n",
        "        'I am so happy today', 'This is amazing', 'I love this so much', 'Feeling joyful', 'Such a wonderful day',\n",
        "        'I feel so sad', 'This is terrible', 'Heartbroken today', 'Feeling down and out', 'Tears in my eyes',\n",
        "        'Wow this is awesome', 'You are the best', 'So excited', 'Absolutely fantastic', 'Incredible work',\n",
        "        'I am so angry', 'This is frustrating', 'Really annoyed', 'Furious right now', 'Mad about this situation',\n",
        "        'Having a great time with friends', 'Enjoying life to the fullest', 'Pure bliss',\n",
        "        'Feeling lonely tonight', 'It\\'s a gloomy day', 'Depressed by the news',\n",
        "        'Adore this song', 'Completely smitten', 'Cannot get enough of this',\n",
        "        'Outraged by the injustice', 'This makes me fume', 'Irritated beyond belief',\n",
        "        'Super thrilled about this', 'Life is beautiful', 'Over the moon',\n",
        "        'So upset right now', 'Feeling miserable', 'Down in the dumps',\n",
        "        'This is so cool', 'Really loving this moment', 'Totally enchanted',\n",
        "        'This is infuriating', 'So mad at this', 'Completely ticked off'\n",
        "    ],\n",
        "    'emoji': ['😊', '😊', '😊', '😊', '😊',\n",
        "              '😢', '😢', '😢', '😢', '😢',\n",
        "              '😍', '😍', '😍', '😍', '😍',\n",
        "              '😡', '😡', '😡', '😡', '😡',\n",
        "              '😊', '😊', '😊',\n",
        "              '😢', '😢', '😢',\n",
        "              '😍', '😍', '😍',\n",
        "              '😡', '😡', '😡',\n",
        "              '😊', '😊', '😊',\n",
        "              '😢', '😢', '😢',\n",
        "              '😍', '😍', '😍',\n",
        "              '😡', '😡', '😡']\n",
        "})"
      ],
      "metadata": {
        "id": "LK2OLfWzZR5M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "EE4VYxgWZW6r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "wSvqQfaZZa1w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_words = 5000\n",
        "max_len = 15\n",
        "embedding_dim = 100\n",
        "epochs = 50\n",
        "batch_size = 8"
      ],
      "metadata": {
        "id": "xBhSUdmtZt9k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(data['text'])\n",
        "sequences = tokenizer.texts_to_sequences(data['text'])\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "kO3zzZ2XZ578"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['emoji'])\n",
        "y = to_categorical(y)"
      ],
      "metadata": {
        "id": "xs9ra4D7Z-aC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "0-MOBP6jaCkM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(glove_file='glove.6B.100d.txt'):\n",
        "    embeddings_index = {}\n",
        "    try:\n",
        "        with open(glove_file, encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                values = line.split()\n",
        "                word = values[0]\n",
        "                coefs = np.asarray(values[1:], dtype='float32')\n",
        "                embeddings_index[word] = coefs\n",
        "        print(f\"Loaded {len(embeddings_index)} GloVe embeddings.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: GloVe file '{glove_file}' not found. Download from \"\n",
        "              \"https://nlp.stanford.edu/projects/glove/ and place in directory.\")\n",
        "\n",
        "        embeddings_index = {word: np.random.rand(embedding_dim) for word in tokenizer.word_index.keys()}\n",
        "    return embeddings_index\n",
        "\n",
        "\n",
        "embeddings_index = load_glove_embeddings()\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zuzs1R6azLB",
        "outputId": "7e48d583-0c81-4949-d5a1-baa7712a3e47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: GloVe file 'glove.6B.100d.txt' not found. Download from https://nlp.stanford.edu/projects/glove/ and place in directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(max_words, embedding_dim, input_length=max_len, weights=[embedding_matrix], trainable=True),\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixVP3afLa1Y4",
        "outputId": "1267ab5f-65a5-49d5-99ba-33f8d1fb4c14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KTEksBE7bAEa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Model Summary ---\")\n",
        "model.summary()\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "9myE1fgCbFMG",
        "outputId": "c6905525-1abe-4bda-88cf-dd0263493767"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Summary ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │       \u001b[38;5;34m500,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)"
      ],
      "metadata": {
        "id": "t1BuVDnIbM2Q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Model Training ---\")\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr, early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"----------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obikrxfJbRsJ",
        "outputId": "2cad51b7-5b68-43a7-f211-25f13fc0f3ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Training ---\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 278ms/step - accuracy: 0.2437 - loss: 1.3958 - val_accuracy: 0.2222 - val_loss: 1.3880 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3079 - loss: 1.3826 - val_accuracy: 0.2222 - val_loss: 1.3899 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2836 - loss: 1.3909 - val_accuracy: 0.2222 - val_loss: 1.3885 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2793 - loss: 1.3877 - val_accuracy: 0.2222 - val_loss: 1.3902 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2741 - loss: 1.3782 - val_accuracy: 0.2222 - val_loss: 1.3894 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.2500 - loss: 1.3492\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1986 - loss: 1.3925 - val_accuracy: 0.2222 - val_loss: 1.3918 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2203 - loss: 1.3797 - val_accuracy: 0.2222 - val_loss: 1.3923 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2801 - loss: 1.3763 - val_accuracy: 0.2222 - val_loss: 1.3940 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2541 - loss: 1.3690 - val_accuracy: 0.2222 - val_loss: 1.3961 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3053 - loss: 1.3714 - val_accuracy: 0.2222 - val_loss: 1.3984 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2660 - loss: 1.3958\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2645 - loss: 1.3945 - val_accuracy: 0.2222 - val_loss: 1.3990 - learning_rate: 5.0000e-04\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"\\n--- Model Evaluation ---\")\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH97mXPPbd4b",
        "outputId": "caf3fa4a-6c23-41f7-9c2b-56912c7cd3c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Evaluation ---\n",
            "Test Loss: 1.3880\n",
            "Test Accuracy: 0.2222\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_texts = [\n",
        "    \"I am super excited\",\n",
        "\n",
        "]\n",
        "\n",
        "print(\"\\n--- Predictions for New Texts ---\")\n",
        "new_texts = [clean_text(text) for text in new_texts]\n",
        "new_sequences = tokenizer.texts_to_sequences(new_texts)\n",
        "new_X = pad_sequences(new_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "predictions = model.predict(new_X, verbose=0)\n",
        "predicted_emojis = label_encoder.inverse_transform(np.argmax(predictions, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSdC61Y_b5c4",
        "outputId": "e8a2fafe-39ce-406d-f471-d78896d113e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Predictions for New Texts ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text, emoji in zip(new_texts, predicted_emojis):\n",
        "    print(f\"Text: '{text}' -> Predicted Emoji: {emoji}\")\n",
        "print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN4qbQYKb_7L",
        "outputId": "75f1d90f-9222-41e5-c443-94e05a48ca05"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'i am super excited' -> Predicted Emoji: 😊\n",
            "---------------------------------\n"
          ]
        }
      ]
    }
  ]
}